{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import time\n",
    "from cvxpy import *\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from scipy.stats import linregress\n",
    "\n",
    "import pylab\n",
    "from matplotlib.animation import FuncAnimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrandomdata(n=100,b=0.):\n",
    "    # generate random data and linearly-separable labels\n",
    "    xTr = np.random.randn(n, 2)\n",
    "    # defining random hyperplane\n",
    "    w0 = np.random.rand(2, 1)\n",
    "    # assigning labels +1, -1 labels depending on what side of the plane they lie on\n",
    "    yTr = np.sign(np.dot(xTr, w0)+b).flatten()\n",
    "    return xTr, yTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primalSVM(xTr, yTr, C=1):\n",
    "    \"\"\"\n",
    "    function (classifier,w,b) = primalSVM(xTr,yTr;C=1)\n",
    "    constructs the SVM primal formulation and uses a built-in \n",
    "    convex solver to find the optimal solution. \n",
    "    \n",
    "    Input:\n",
    "        xTr   | training data (nxd)\n",
    "        yTr   | training labels (n)\n",
    "        C     | the SVM regularization parameter\n",
    "    \n",
    "    Output:\n",
    "        fun   | a prediction function, usage: predictions=fun(xTe); where predictions.shape = (n,)\n",
    "        wout  | the weight vector calculated by the solver\n",
    "        bout  | the bias term calculated by the solver\n",
    "    \"\"\"\n",
    "    N, d = xTr.shape\n",
    "    y = yTr.flatten()\n",
    "    # example code: an example of establishing objective and constraints, and how to let the solver solve it.\n",
    "    #w = Variable(d)\n",
    "    #b = Variable(1)\n",
    "    #objective = sum_squares(w)\n",
    "    #constraints = [w >= 0]\n",
    "    #prob = Problem(Minimize(objective), constraints)\n",
    "    #prob.solve()\n",
    "    #wout = w.value\n",
    "    #bout = b.value\n",
    "    # End of example code\n",
    "    \n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayify(x):\n",
    "    \"\"\"flattens and converts to numpy\"\"\"\n",
    "    return np.array(x).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr,yTr=genrandomdata()\n",
    "fun,w,b=primalSVM(xTr,yTr,C=10)\n",
    "utils.visclassifier(fun,xTr,yTr,w=w,b=b)\n",
    "\n",
    "\n",
    "err=np.mean(arrayify(np.sign(fun(xTr)))!=yTr)\n",
    "print(\"Training error: %2.1f%%\" % (err*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testCase_Primal():\n",
    "    Clocal = 1\n",
    "    trainX = np.array([[0,0],[0,1],[0,2],[1,0],[1,1],[1,2],[2,0],[2,1],[2,2]]) \n",
    "    trainY = np.array([1,1,1,-1,1,1,-1,-1,1])\n",
    "    fun_Primal,_,_ = primalSVM(trainX,trainY,C=Clocal)\n",
    "\n",
    "    testX = np.array([[1.6,0.4],[1.4,1.6],[0.4,0.6],[0.4,1.6]])\n",
    "    testY = np.array([-1,1,1,1])\n",
    "    resultY = fun_Primal(testX)\n",
    "    boolArray = (np.sign(resultY)==testY).tolist()\n",
    "    signMatch = all(boolArray)\n",
    "    return signMatch\n",
    "print('primalSVM passes sign match test: ' + str(testCase_Primal()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateboundary():\n",
    "    global w,b,Xdata,ldata,stepsize\n",
    "\n",
    "    _, w_pre, b_pre = primalSVM(np.transpose(Xdata),np.array(ldata),C=10)\n",
    "    w = np.array(w_pre).reshape(-1)\n",
    "    b = b_pre\n",
    "    stepsize+=1\n",
    "\n",
    "def updatescreen():\n",
    "    global w,b,ax,line \n",
    "    q=-b/(w**2).sum()*w;\n",
    "    if line==None:\n",
    "        line, = ax.plot([q[0]-w[1],q[0]+w[1]],[q[1]+w[0],q[1]-w[0]],'b--')\n",
    "    else:\n",
    "        line.set_ydata([q[1]+w[0],q[1]-w[0]])\n",
    "        line.set_xdata([q[0]-w[1],q[0]+w[1]])\n",
    "    \n",
    "def animate(i):\n",
    "    #if len(ldata)>0 and ((min(ldata)+max(ldata))==0):\n",
    "    if (len(ldata)>0) and ((np.min(ldata)+np.max(ldata))==0):\n",
    "        if stepsize<1000:\n",
    "            updateboundary()\n",
    "            updatescreen();\n",
    "    \n",
    "def onclick(event):\n",
    "    global Xdata, stepsize  \n",
    "    if event.key == 'shift': # add positive point\n",
    "        ax.plot(event.xdata,event.ydata,'or')\n",
    "        label=1\n",
    "    else: # add negative point\n",
    "        ax.plot(event.xdata,event.ydata,'ob')\n",
    "        label=-1    \n",
    "    pos=np.array([[event.xdata],[event.ydata]])\n",
    "    ldata.append(label);\n",
    "    Xdata=np.hstack((Xdata,pos))\n",
    "    stepsize=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata=np.random.rand(2,0)\n",
    "ldata=[]\n",
    "w=[]\n",
    "b=[]\n",
    "line=None\n",
    "stepsize=1;\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "ani = FuncAnimation(fig, animate,np.arange(1,100,1),interval=10);\n",
    "plt.title('Use shift-click to add negative points.')\n",
    "# Note that it is easy to generate odd decision boundaries, particularly if data is not easily linearly separable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spiraldata(N=300):\n",
    "    r = np.linspace(1,2*np.pi,N)\n",
    "    xTr1 = np.array([np.sin(2.*r)*r, np.cos(2*r)*r]).T\n",
    "    xTr2 = np.array([np.sin(2.*r+np.pi)*r, np.cos(2*r+np.pi)*r]).T\n",
    "    xTr = np.concatenate([xTr1, xTr2], axis=0)\n",
    "    yTr = np.concatenate([np.ones(N), -1 * np.ones(N)])\n",
    "    xTr = xTr + np.random.randn(xTr.shape[0], xTr.shape[1])*0.2\n",
    "    \n",
    "    xTe = xTr[::2,:]\n",
    "    yTe = yTr[::2]\n",
    "    xTr = xTr[1::2,:]\n",
    "    yTr = yTr[1::2]\n",
    "    \n",
    "    return xTr,yTr,xTe,yTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr,yTr,xTe,yTe=spiraldata()\n",
    "fig = plt.figure()\n",
    "plt.scatter(xTr[yTr == 1, 0], xTr[yTr == 1, 1], c='b')\n",
    "plt.scatter(xTr[yTr != 1, 0], xTr[yTr != 1, 1], c='r')\n",
    "plt.legend([\"+1\",\"-1\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun,w,b=primalSVM(xTr,yTr,C=0.01)\n",
    "utils.visclassifier(fun,xTr,yTr,w=[],b=0)\n",
    "err=np.mean(arrayify(np.sign(fun(xTr)))!=yTr)\n",
    "print(\"Training error: %2.1f%%\" % (err*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeK(kerneltype, X, Z, kpar=0):\n",
    "    \"\"\"\n",
    "    function K = computeK(kernel_type, X, Z)\n",
    "    computes a matrix K such that Kij=k(x,z);\n",
    "    for three different function linear, rbf or polynomial.\n",
    "    \n",
    "    Input:\n",
    "    kerneltype: either 'linear','polynomial','rbf'\n",
    "    X: n input vectors of dimension d (nxd);\n",
    "    Z: m input vectors of dimension d (mxd);\n",
    "    kpar: kernel parameter (inverse kernel width gamma in case of RBF, degree in case of polynomial)\n",
    "    \n",
    "    OUTPUT:\n",
    "    K : nxm kernel matrix\n",
    "    \"\"\"\n",
    "    assert kerneltype in [\"linear\",\"polynomial\",\"poly\",\"rbf\"], \"Kernel type %s not known.\" % kerneltype\n",
    "    assert X.shape[1] == Z.shape[1], \"Input dimensions do not match\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isClose(num1,num2,numtol=1e-3):\n",
    "    return np.abs(num1-num2)<numtol\n",
    "\n",
    "def isMatClose(X1,X2,tol=1e-3):\n",
    "    a,b = X1.shape\n",
    "    output = True\n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            output = output and isClose(X1[i][j],X2[i][j],numtol=tol)\n",
    "    return output \n",
    "\n",
    "def testCase_computeK_linear():\n",
    "    X = np.array([[9],[0]])\n",
    "    Z = np.array([[1],[3]])\n",
    "    K = computeK('linear',X,Z)\n",
    "    K = np.array(K)\n",
    "    check = isMatClose(K,np.array([[9,27],[0,0]])) \n",
    "    return check\n",
    "\n",
    "print('computeK passes test for linear kernel: ' + str(testCase_computeK_linear()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr,yTr,xTe,yTe=spiraldata()\n",
    "K=computeK(\"rbf\",xTr,xTr,kpar=0.05)\n",
    "# plot an image of the kernel matrix\n",
    "fig = plt.figure()\n",
    "plt.pcolormesh(K, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dualqp(K,yTr,C):\n",
    "    \"\"\"\n",
    "    function alpha = dualqp(K,yTr,C)\n",
    "    constructs the SVM dual formulation and uses a built-in \n",
    "    convex solver to find the optimal solution. \n",
    "    \n",
    "    Input:\n",
    "        K     | the (nxn) kernel matrix\n",
    "        yTr   | training labels (nx1)\n",
    "        C     | the SVM regularization parameter\n",
    "    \n",
    "    Output:\n",
    "        alpha | the calculated solution vector (nx1)\n",
    "    \"\"\"\n",
    "    y = yTr.flatten()\n",
    "    N, _ = K.shape\n",
    "    alpha = Variable(N)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "lmbda = 0.25\n",
    "ktype = \"rbf\"\n",
    "xTr,yTr,xTe,yTe=spiraldata()\n",
    "# compute kernel (make sure it is PSD)\n",
    "K = computeK(ktype,xTr,xTr)\n",
    "eps = 1e-8\n",
    "# make sure it is symmetric and positive semi-definite\n",
    "K = (K + K.T) / 2 + eps * np.eye(K.shape[0])\n",
    "\n",
    "alpha = dualqp(K,yTr,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverBias(K,yTr,alpha,C):\n",
    "    \"\"\"\n",
    "    function bias=recoverBias(K,yTr,alpha,C);\n",
    "    Solves for the hyperplane bias term, which is uniquely specified by the \n",
    "    support vectors with alpha values 0<alpha<C\n",
    "    \n",
    "    INPUT:\n",
    "    K : nxn kernel matrix\n",
    "    yTr : nx1 input labels\n",
    "    alpha  : nx1 vector of alpha values\n",
    "    C : regularization constant\n",
    "    \n",
    "    Output:\n",
    "    bias : the scalar hyperplane bias of the kernel SVM specified by alphas\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr,yTr=genrandomdata(b=0.5)\n",
    "C=1\n",
    "K=computeK(\"linear\",xTr,xTr)\n",
    "eps=1e-8\n",
    "K = (K + K.T) / 2 + eps * np.eye(K.shape[0])\n",
    "alpha = dualqp(K,yTr,C)\n",
    "ba=recoverBias(K,yTr,alpha,C)\n",
    "wa = (alpha * yTr).dot(xTr)\n",
    "fun = lambda x: x.dot(wa) + ba\n",
    "visclassifier(fun, xTr, yTr, w=wa, b=ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dualSVM(xTr,yTr,C,ktype,lmbda,eps=1e-8):\n",
    "    \"\"\"\n",
    "    function classifier = dualSVM(xTr,yTr,C,ktype,lmbda);\n",
    "    Constructs the SVM dual formulation and uses a built-in \n",
    "    convex solver to find the optimal solution. \n",
    "    \n",
    "    Input:\n",
    "        xTr   | training data (nxd)\n",
    "        yTr   | training labels (nx1)\n",
    "        C     | the SVM regularization parameter\n",
    "        ktype | the type of kernelization: 'rbf','polynomial','linear'\n",
    "        lmbda | the kernel parameter - degree for poly, inverse width for rbf\n",
    "    \n",
    "    Output:\n",
    "        svmclassify | usage: predictions=svmclassify(xTe);\n",
    "    \"\"\"\n",
    "    #K_new = ((K + K.T) / 2 ) + (eps * np.eye(K.shape[0]))    \n",
    "    #assert K_new.all() == K.all(), \"The kernel matrix is not positive semi-definite\"   \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTr,yTr,xTe,yTe=spiraldata()\n",
    "C=10.0\n",
    "sigma=10.0 # Note: If sigma is too small you may get convergence errors.\n",
    "ktype=\"rbf\"\n",
    "svmclassify=dualSVM(xTr,yTr,C,ktype,sigma)\n",
    "\n",
    "utils.visclassifier(svmclassify,xTr,yTr)\n",
    "\n",
    "# compute training and testing error\n",
    "predsTr=svmclassify(xTr)\n",
    "trainingerr=np.mean(np.sign(predsTr)!=yTr)\n",
    "print(\"Training error: %2.4f\" % trainingerr)\n",
    "\n",
    "predsTe=svmclassify(xTe)\n",
    "testingerr=np.mean(np.sign(predsTe)!=yTe)\n",
    "print(\"Testing error: %2.4f\" % testingerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(xTr,yTr,xValid,yValid,ktype,CList,lmbdaList):\n",
    "    \"\"\"\n",
    "    function bestC,bestLmbda,ErrorMatrix = cross_validation(xTr,yTr,xValid,yValid,ktype,CList,lmbdaList);\n",
    "    Use the parameter search to find the optimal parameter,\n",
    "    Individual models are trained on (xTr,yTr) while validated on (xValid,yValid)\n",
    "    \n",
    "    Input:\n",
    "        xTr      | training data (nxd)\n",
    "        yTr      | training labels (nx1)\n",
    "        xValid   | training data (mxd)\n",
    "        yValid   | training labels (mx1)\n",
    "        ktype    | the type of kernelization: 'rbf','polynomial','linear'\n",
    "        CList    | The list of values to try for the SVM regularization parameter C (ax1)\n",
    "        lmbdaList| The list of values to try for the kernel parameter lmbda- degree for poly, inverse width for rbf (bx1)\n",
    "    \n",
    "    Output:\n",
    "        bestC      | the best C parameter\n",
    "        bestLmbda  | the best Lmbda parameter\n",
    "        ErrorMatrix| the test error rate for each given C and Lmbda when trained on (xTr,yTr) and tested on (xValid,yValid),(axb)\n",
    "    \"\"\"\n",
    "    # gridsearch for best parameters\n",
    "    ErrorMatrix=np.zeros((len(CList),len(lmbdaList)))\n",
    "    bestC,bestLmbda = 0.,0.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(15)\n",
    "xTr,yTr,xValid,yValid=spiraldata(100)\n",
    "CList=(2.0**np.linspace(-2,1,7))\n",
    "lmbdaList=(np.linspace(1.0,15,7))\n",
    "\n",
    "bestC,bestLmbda,ErrorMatrix = cross_validation(xTr,yTr,xValid,yValid,'rbf',CList,lmbdaList)\n",
    "fig = plt.figure()\n",
    "plt.pcolormesh(ErrorMatrix, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"lmbda_idx\")\n",
    "plt.ylabel(\"C_idx\")\n",
    "plt.title(\"Validation error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe3f05434994f8f40b62b7a842a4d284a09e5cdb62d98927152580f7c19a8881"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
